{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_model.ipynb의 사본의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MN5CdI3LSnW",
        "colab_type": "text"
      },
      "source": [
        "소스 출처 : https://tykimos.github.io/2017/01/27/Keras_Talk/\n",
        "\n",
        "https://tykimos.github.io/lecture/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDUzCm2WKryu",
        "colab_type": "code",
        "outputId": "c103e5bf-2392-43ab-c589-80323dc99140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mogUGHxoK-Zv",
        "colab_type": "code",
        "outputId": "0d753704-8cc7-48f8-e109-4c8b3a024239",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 1. 데이터셋 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('x_train의 shape :')\n",
        "print('{} \\n'.format(x_train.shape))\n",
        "print('x_train의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(x_train[0]))\n",
        "print('='*60)\n",
        "print('x_test의 shape :')\n",
        "print('{} \\n'.format(x_test.shape))\n",
        "print('x_test의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(x_test[0]))      \n",
        "print('='*60)\n",
        "\n",
        "# MNIST 첫번째 부터 10번째 까지 데이터 보기\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "figure = plt.figure()\n",
        "figure.set_size_inches(12, 5)\n",
        "axes = []\n",
        "for i in range(1, 11):\n",
        "  axes.append(figure.add_subplot(2, 5, i))\n",
        "for i in range(10):\n",
        "  axes[i].matshow(x_train[i])\n",
        "\n",
        "# 1-1. 데이터셋을 학습용(x_train, y_train)과 평가용(x_test, y_test)으로 나누기\n",
        "x_train = x_train.reshape(60000, 784).astype('float32') / 255.0    #28곱하기 28은 784\n",
        "x_test = x_test.reshape(10000, 784).astype('float32') / 255.0\n",
        "\n",
        "print('reshape 후의 x_train의 shape :') \n",
        "print('{} \\n'.format(x_train.shape))\n",
        "print('reshape 후의 x_train의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(x_train[0]))\n",
        "print('='*60)\n",
        "print('reshape 후의 x_test의 shape :')\n",
        "print('{} \\n'.format(x_test.shape))\n",
        "print('reshape 후의 x_test의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(x_test[0])) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train의 shape :\n",
            "(60000, 28, 28) \n",
            "\n",
            "x_train의 첫 번째 데이터 :\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "============================================================\n",
            "x_test의 shape :\n",
            "(10000, 28, 28) \n",
            "\n",
            "x_test의 첫 번째 데이터 :\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  84 185 159 151  60  36   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 222 254 254 254 254 241 198 198 198 198 198 198\n",
            "  198 198 170  52   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  67 114  72 114 163 227 254 225 254 254 254 250\n",
            "  229 254 254 140   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  17  66  14  67  67  67  59\n",
            "   21 236 254 106   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   83 253 209  18   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22\n",
            "  233 255  83   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 129\n",
            "  254 238  44   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  59 249\n",
            "  254  62   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 133 254\n",
            "  187   5   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   9 205 248\n",
            "   58   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 126 254 182\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  75 251 240  57\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  19 221 254 166   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3 203 254 219  35   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  38 254 254  77   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  31 224 254 115   1   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 133 254 254  52   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  61 242 254 254  52   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 254 219  40   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 121 254 207  18   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]] \n",
            "\n",
            "============================================================\n",
            "reshape 후의 x_train의 shape :\n",
            "(60000, 784) \n",
            "\n",
            "reshape 후의 x_train의 첫 번째 데이터 :\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ] \n",
            "\n",
            "============================================================\n",
            "reshape 후의 x_test의 shape :\n",
            "(10000, 784) \n",
            "\n",
            "reshape 후의 x_test의 첫 번째 데이터 :\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.32941177 0.7254902\n",
            " 0.62352943 0.5921569  0.23529412 0.14117648 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.87058824 0.99607843 0.99607843 0.99607843\n",
            " 0.99607843 0.94509804 0.7764706  0.7764706  0.7764706  0.7764706\n",
            " 0.7764706  0.7764706  0.7764706  0.7764706  0.6666667  0.20392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.2627451  0.44705883 0.28235295 0.44705883 0.6392157  0.8901961\n",
            " 0.99607843 0.88235295 0.99607843 0.99607843 0.99607843 0.98039216\n",
            " 0.8980392  0.99607843 0.99607843 0.54901963 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.06666667 0.25882354 0.05490196\n",
            " 0.2627451  0.2627451  0.2627451  0.23137255 0.08235294 0.9254902\n",
            " 0.99607843 0.41568628 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3254902  0.99215686 0.81960785 0.07058824\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.08627451\n",
            " 0.9137255  1.         0.3254902  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.5058824  0.99607843 0.93333334\n",
            " 0.17254902 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.23137255 0.9764706  0.99607843 0.24313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.52156866 0.99607843\n",
            " 0.73333335 0.01960784 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.03529412 0.8039216  0.972549   0.22745098 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.49411765\n",
            " 0.99607843 0.7137255  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.29411766 0.9843137  0.9411765  0.22352941\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.07450981\n",
            " 0.8666667  0.99607843 0.6509804  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.79607844 0.99607843 0.85882354\n",
            " 0.13725491 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.14901961 0.99607843 0.99607843 0.3019608  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.12156863 0.8784314  0.99607843\n",
            " 0.4509804  0.00392157 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.52156866 0.99607843 0.99607843 0.20392157 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.23921569 0.9490196\n",
            " 0.99607843 0.99607843 0.20392157 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.4745098  0.99607843 0.99607843 0.85882354\n",
            " 0.15686275 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.4745098  0.99607843 0.8117647  0.07058824 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsMAAAEqCAYAAADwL12VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASC0GwwAAAEgtBsMAAABIrf8fLIIYh6mGOn0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x360 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eyCFOYPRZlU",
        "colab_type": "code",
        "outputId": "87c777d7-af85-4a34-fc9d-4cff6f750fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "print('y_train의 shape : {}'.format(y_train.shape))\n",
        "print('y_train의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(y_train[0]))\n",
        "print('='*60)\n",
        "print('y_test의 shape : {}'.format(y_test.shape))\n",
        "print('y_test의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(y_test[0])) \n",
        "print('='*60)\n",
        "      \n",
        "y_train = np_utils.to_categorical(y_train) #원핫인코딩 해준것.\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "print('to_categorical 후의 y_train의 shape : {}'.format(y_train.shape))\n",
        "print('to_categorical 후의 y_train의 첫 번째 데이터 :')\n",
        "print('{} \\n'.format(y_train[0]))\n",
        "print('='*60)\n",
        "print('to_categorical 후의 x_test의 shape : {}'.format(x_test.shape))\n",
        "print('to_categorical 후의 x_test의 첫 번째 데이터 :')\n",
        "print('{}'.format(y_test[0])) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train의 shape : (60000,)\n",
            "y_train의 첫 번째 데이터 :\n",
            "5 \n",
            "\n",
            "============================================================\n",
            "y_test의 shape : (10000,)\n",
            "y_test의 첫 번째 데이터 :\n",
            "7 \n",
            "\n",
            "============================================================\n",
            "to_categorical 후의 y_train의 shape : (60000, 10)\n",
            "to_categorical 후의 y_train의 첫 번째 데이터 :\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] \n",
            "\n",
            "============================================================\n",
            "to_categorical 후의 x_test의 shape : (10000, 784)\n",
            "to_categorical 후의 x_test의 첫 번째 데이터 :\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaAXQiC7K09d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(units=64, input_dim=28*28, activation='relu')) #units는 가중치(=특징 )개수, 뭔지는 모르겠으나 특징 64개를 만들어줘. 33개로 만들어줘. 등등 // 첫줄에만 inputdim을 넣어주고 다음부터는 안넣어준다.\n",
        "# model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax')) #레이터2에서는 가중치를 10개로 하겠어.마지막은 softmax . 이게 왜 마지막이냐며는 0~9까지 분류기때문에 마지막 클래스가 총 10개여서/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pm88oRDK01p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 모델 학습과정 설정하기.-> 이 방법을 통해서 가중치 최적화를 할것이다. =(loss를 최소로 하는것)loss의 식이 범주형이기떄문에 categorical 사용가능 ,optimizer  sgd라는 모델을 쓰겠따.)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) #matrics는 평가지표라고 보면됨...정확도를 가지고 최적화를 시키겠다..\n",
        "#loss를 최소화하기위한 과정!이렇게 할꺼다라는 과정을 설정해준것임..아직 실행한것은 아님. 학습은 fit에서 됨."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqH-dNBuK0uG",
        "colab_type": "code",
        "outputId": "9eda1620-2775-4bff-9858-a94c7f7985a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(x_train, y_train, epochs=5, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.6720 - acc: 0.8269\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.3443 - acc: 0.9039\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.2962 - acc: 0.9169\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.2666 - acc: 0.9249\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.2448 - acc: 0.9314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udJcG91tK0m9",
        "colab_type": "code",
        "outputId": "94e58f72-7d1e-438b-bbc4-ea17f00f32ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# 5. 학습과정 살펴보기\n",
        "print('## training loss ##')\n",
        "print(hist.history['loss'], '\\n')\n",
        "print('## training accuracy ##')\n",
        "print(hist.history['acc'])\n",
        "#오차는 내려가고 정확도는 올라감다."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## training loss ##\n",
            "[0.6719846527655919, 0.344281359521548, 0.29616562617818515, 0.2666338012079398, 0.24479538332422573] \n",
            "\n",
            "## training accuracy ##\n",
            "[0.82695, 0.9039, 0.91685, 0.9248833333333333, 0.93135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2M9NxO3K0gT",
        "colab_type": "code",
        "outputId": "8bfb5c37-1875-45bf-c9a5-e540d7374fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# 6. 모델 평가하기\n",
        "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print('## evaluation loss and accuracy ##')\n",
        "print(loss_and_metrics)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 55us/step\n",
            "## evaluation loss and accuracy ##\n",
            "[0.22867498847842216, 0.9334]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GuvkXLIK0VM",
        "colab_type": "code",
        "outputId": "b1c8bcc5-4ac4-4bb0-8dd2-077757a995a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# 7. 모델 사용하기\n",
        "xhat = x_test[0:1] # 왜 이렇게 넣는지 하단에서 설명\n",
        "#한개만 돌려보고싶은게 아니라면 xhat = x_test[x_tets]]  요로케 해주면 됨 \n",
        "yhat = model.predict(xhat)\n",
        "print('## yhat ##')\n",
        "print(yhat)\n",
        "#9.9277955e 이게 제일 높은값이다.  7번째값"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "## yhat ##\n",
            "[[2.3402083e-04 1.3906413e-07 5.8333226e-04 2.3853909e-03 5.2451505e-06\n",
            "  1.1700177e-04 1.6789988e-07 9.9277955e-01 1.1604963e-04 3.7791603e-03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcdft6H7PCaO",
        "colab_type": "code",
        "outputId": "3a824fca-7618-40b0-abab-efa0f2695cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test[0] #7번째가 가장높으니가 잘 예측한것."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWtEGzn3ONJs",
        "colab_type": "code",
        "outputId": "7226b7c8-ff4b-4d73-c39a-75188abb2d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM87sUXpLmhD",
        "colab_type": "code",
        "outputId": "7534d338-2727-40df-ead9-9f2aacf4b416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# ValueError: Error when checking input: expected dense_1_input to have shape (784,) but got array with shape (1,)\n",
        "\n",
        "x_test[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR4l5y00LOCD",
        "colab_type": "code",
        "outputId": "7cf59ba7-df8e-4a12-9227-45af076b8af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_test[0:1].shape  # 0:1 을 해주는 이유는 (1,784)인 형태로 넣어주기 위함."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY7l811wN4u6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
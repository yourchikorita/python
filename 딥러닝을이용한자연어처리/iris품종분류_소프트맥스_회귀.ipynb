{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris_소프트맥스 회귀.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqEeCJ49enyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UWlAqoDerKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReWEJWUaeuzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "df325113-3a37-4c22-a638-1d834d0f6eab"
      },
      "source": [
        "iris=load_iris()\n",
        "iris.keys()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pim3iSPZeyCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "0551f8b7-a21b-44d4-f274-e4e27388ae2a"
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal length (cm)',\n",
              " 'sepal width (cm)',\n",
              " 'petal length (cm)',\n",
              " 'petal width (cm)']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piAZ30Sqe7Ep",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "59aaa332-6264-48d7-b347-39af15cf1700"
      },
      "source": [
        "print(iris.feature_names)\n",
        "print(iris.data[:5])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFQjQiSVfRPB",
        "colab_type": "text"
      },
      "source": [
        "각각 나타냄\n",
        "sepal length (cm)',\n",
        " 'sepal width (cm)',\n",
        " 'petal length (cm)',\n",
        " 'petal width (cm)'\n",
        " <hr>\n",
        " 우리가 나타내고자하는 3가지 꽃 클래스는\n",
        " 0은 setosa,\n",
        " 1은 versicolor\n",
        " 2는 virginica\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqhQhBG6e_3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf63b4d3-ab5a-4135-d256-8585353998d1"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez84VG4OfrGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "da09d33d-bcb0-4783-ff32-31ed0e226491"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEK_8GHVftI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a706924-cc54-4515-c3f0-a6dd6e69573c"
      },
      "source": [
        "len(iris.data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iae1uopCfvu8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21ba9edd-8cbf-4ad6-fd55-6ae0eb8c1c0b"
      },
      "source": [
        "len(iris.target)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AILILX5ugh0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "fef5d7b9-c94c-4156-bb85-3fadbfd0a142"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "data_X = iris.data # X 데이터에 해당됩니다. X는 총 4개입니다.\n",
        "data_y = iris.target # Y 데이터에 해당됩니다. 예측해야하는 값입니다.\n",
        "\n",
        "print(data_X[:10]) #X에 해당되는 데이터를 10개만 출력합니다.\n",
        "print(data_y[:10]) #y에 해당되는 데이터를 10개만 출력합니다."
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]]\n",
            "[0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr6bEuVXiczU",
        "colab_type": "text"
      },
      "source": [
        "이제 훈련 데이터와 테스트 데이터의 분리와 원-핫 인코딩을 수행해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Is-6Ud8jdCN",
        "colab_type": "text"
      },
      "source": [
        "to_categorical -> onehot encoding처리\n",
        "\n",
        "OneHot Encoding\n",
        "\n",
        "* 컴퓨터가 이해할수 있는 label로 바꾸기 \n",
        "\n",
        "5 -> [0,0,0,0,0,1,0,0,0,0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTpL3KIPgwJ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "b14dcee6-55ce-428c-9b50-1c75fa6e9a3b"
      },
      "source": [
        "(X_train, X_test, y_train, y_test) = train_test_split(data_X, data_y, train_size=0.8, random_state=1)\n",
        "# 훈련 데이터와 테스트 데이터를 8:2로 나눕니다. 또한 데이터의 순서를 섞습니다.\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test) \n",
        "# 훈련 데이터와 테스트 데이터에 대해서 원-핫 인코딩\n",
        "print(y_train[:5])\n",
        "print(y_test[:5])\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF_p1IzskFSG",
        "colab_type": "text"
      },
      "source": [
        "### 2) 소프트맥스 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbD95ljgiilH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d171fe0-b466-4514-c228-23aa3ad454a1"
      },
      "source": [
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
        "sgd=optimizers.SGD(lr=0.01)\n",
        "# 학습률(learning rate, lr)은 0.01로 합니다.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "# 옵티마이저는 경사하강법의 일종인 adam을 사용합니다.\n",
        "# 손실 함수(Loss function)은 평균제곱오차 크로스 엔트로피 함수를 사용합니다.\n",
        "history=model.fit(X_train,y_train, batch_size=1, epochs=200, validation_data=(X_test, y_test))\n",
        "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다."
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Train on 120 samples, validate on 30 samples\n",
            "Epoch 1/200\n",
            "120/120 [==============================] - 0s 4ms/sample - loss: 3.0132 - acc: 0.3083 - val_loss: 1.9308 - val_acc: 0.4333\n",
            "Epoch 2/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 1.5694 - acc: 0.3083 - val_loss: 1.0528 - val_acc: 0.4333\n",
            "Epoch 3/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.8416 - acc: 0.5333 - val_loss: 0.7613 - val_acc: 0.5667\n",
            "Epoch 4/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.6430 - acc: 0.7000 - val_loss: 0.6808 - val_acc: 0.6333\n",
            "Epoch 5/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.5745 - acc: 0.8250 - val_loss: 0.6435 - val_acc: 0.6667\n",
            "Epoch 6/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.5445 - acc: 0.8500 - val_loss: 0.6334 - val_acc: 0.6333\n",
            "Epoch 7/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.5277 - acc: 0.8000 - val_loss: 0.6007 - val_acc: 0.7000\n",
            "Epoch 8/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.5130 - acc: 0.8667 - val_loss: 0.6004 - val_acc: 0.7000\n",
            "Epoch 9/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.5051 - acc: 0.8000 - val_loss: 0.5756 - val_acc: 0.7000\n",
            "Epoch 10/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4919 - acc: 0.8417 - val_loss: 0.5693 - val_acc: 0.7000\n",
            "Epoch 11/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4810 - acc: 0.8750 - val_loss: 0.5514 - val_acc: 0.7333\n",
            "Epoch 12/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4737 - acc: 0.8917 - val_loss: 0.5467 - val_acc: 0.7000\n",
            "Epoch 13/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4659 - acc: 0.8417 - val_loss: 0.5354 - val_acc: 0.7333\n",
            "Epoch 14/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4556 - acc: 0.9000 - val_loss: 0.5363 - val_acc: 0.7000\n",
            "Epoch 15/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4498 - acc: 0.8583 - val_loss: 0.5138 - val_acc: 0.7333\n",
            "Epoch 16/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4402 - acc: 0.8833 - val_loss: 0.5018 - val_acc: 0.7333\n",
            "Epoch 17/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4355 - acc: 0.8917 - val_loss: 0.5034 - val_acc: 0.7333\n",
            "Epoch 18/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4270 - acc: 0.8917 - val_loss: 0.4899 - val_acc: 0.7333\n",
            "Epoch 19/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4224 - acc: 0.9000 - val_loss: 0.4890 - val_acc: 0.7333\n",
            "Epoch 20/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4158 - acc: 0.9083 - val_loss: 0.4985 - val_acc: 0.7000\n",
            "Epoch 21/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4121 - acc: 0.9000 - val_loss: 0.4783 - val_acc: 0.7333\n",
            "Epoch 22/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.4061 - acc: 0.9000 - val_loss: 0.4691 - val_acc: 0.7333\n",
            "Epoch 23/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3998 - acc: 0.9333 - val_loss: 0.4668 - val_acc: 0.7333\n",
            "Epoch 24/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3953 - acc: 0.9167 - val_loss: 0.4633 - val_acc: 0.7333\n",
            "Epoch 25/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3933 - acc: 0.9250 - val_loss: 0.4654 - val_acc: 0.7333\n",
            "Epoch 26/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3872 - acc: 0.8917 - val_loss: 0.4522 - val_acc: 0.7333\n",
            "Epoch 27/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3831 - acc: 0.9083 - val_loss: 0.4348 - val_acc: 0.9000\n",
            "Epoch 28/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3807 - acc: 0.9583 - val_loss: 0.4451 - val_acc: 0.7333\n",
            "Epoch 29/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3756 - acc: 0.9583 - val_loss: 0.4619 - val_acc: 0.7333\n",
            "Epoch 30/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3725 - acc: 0.9083 - val_loss: 0.4470 - val_acc: 0.7333\n",
            "Epoch 31/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3682 - acc: 0.9167 - val_loss: 0.4345 - val_acc: 0.7333\n",
            "Epoch 32/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3645 - acc: 0.9167 - val_loss: 0.4252 - val_acc: 0.8000\n",
            "Epoch 33/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3616 - acc: 0.9167 - val_loss: 0.4205 - val_acc: 0.8000\n",
            "Epoch 34/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3587 - acc: 0.9500 - val_loss: 0.4156 - val_acc: 0.8667\n",
            "Epoch 35/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3524 - acc: 0.9667 - val_loss: 0.4361 - val_acc: 0.7333\n",
            "Epoch 36/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3540 - acc: 0.9083 - val_loss: 0.4239 - val_acc: 0.7333\n",
            "Epoch 37/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3473 - acc: 0.9500 - val_loss: 0.4093 - val_acc: 0.8000\n",
            "Epoch 38/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3450 - acc: 0.9250 - val_loss: 0.4160 - val_acc: 0.7333\n",
            "Epoch 39/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3399 - acc: 0.9417 - val_loss: 0.3943 - val_acc: 0.9000\n",
            "Epoch 40/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3374 - acc: 0.9667 - val_loss: 0.4000 - val_acc: 0.8667\n",
            "Epoch 41/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3382 - acc: 0.9417 - val_loss: 0.4093 - val_acc: 0.7333\n",
            "Epoch 42/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3338 - acc: 0.8917 - val_loss: 0.3868 - val_acc: 0.9000\n",
            "Epoch 43/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3310 - acc: 0.9583 - val_loss: 0.3797 - val_acc: 0.9000\n",
            "Epoch 44/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3313 - acc: 0.9500 - val_loss: 0.3795 - val_acc: 0.9000\n",
            "Epoch 45/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3254 - acc: 0.9333 - val_loss: 0.3752 - val_acc: 0.9000\n",
            "Epoch 46/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3212 - acc: 0.9583 - val_loss: 0.3929 - val_acc: 0.8000\n",
            "Epoch 47/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3224 - acc: 0.9333 - val_loss: 0.3702 - val_acc: 0.9000\n",
            "Epoch 48/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3153 - acc: 0.9583 - val_loss: 0.3816 - val_acc: 0.8667\n",
            "Epoch 49/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3134 - acc: 0.9333 - val_loss: 0.3637 - val_acc: 0.9000\n",
            "Epoch 50/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3121 - acc: 0.9667 - val_loss: 0.3682 - val_acc: 0.9000\n",
            "Epoch 51/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3084 - acc: 0.9500 - val_loss: 0.3624 - val_acc: 0.9000\n",
            "Epoch 52/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3062 - acc: 0.9667 - val_loss: 0.3699 - val_acc: 0.8667\n",
            "Epoch 53/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3041 - acc: 0.9667 - val_loss: 0.3657 - val_acc: 0.9000\n",
            "Epoch 54/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.3014 - acc: 0.9667 - val_loss: 0.3738 - val_acc: 0.8333\n",
            "Epoch 55/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2991 - acc: 0.9583 - val_loss: 0.3594 - val_acc: 0.9000\n",
            "Epoch 56/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2962 - acc: 0.9833 - val_loss: 0.3611 - val_acc: 0.9000\n",
            "Epoch 57/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2945 - acc: 0.9333 - val_loss: 0.3450 - val_acc: 0.9333\n",
            "Epoch 58/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2946 - acc: 0.9750 - val_loss: 0.3490 - val_acc: 0.9000\n",
            "Epoch 59/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2929 - acc: 0.9583 - val_loss: 0.3422 - val_acc: 0.9333\n",
            "Epoch 60/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2872 - acc: 0.9750 - val_loss: 0.3451 - val_acc: 0.9000\n",
            "Epoch 61/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2850 - acc: 0.9500 - val_loss: 0.3401 - val_acc: 0.9000\n",
            "Epoch 62/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2858 - acc: 0.9750 - val_loss: 0.3391 - val_acc: 0.9000\n",
            "Epoch 63/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2827 - acc: 0.9417 - val_loss: 0.3290 - val_acc: 0.9333\n",
            "Epoch 64/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2799 - acc: 0.9750 - val_loss: 0.3480 - val_acc: 0.8667\n",
            "Epoch 65/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2785 - acc: 0.9583 - val_loss: 0.3379 - val_acc: 0.9000\n",
            "Epoch 66/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2768 - acc: 0.9750 - val_loss: 0.3288 - val_acc: 0.9333\n",
            "Epoch 67/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2760 - acc: 0.9750 - val_loss: 0.3360 - val_acc: 0.9000\n",
            "Epoch 68/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2743 - acc: 0.9667 - val_loss: 0.3609 - val_acc: 0.8000\n",
            "Epoch 69/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2740 - acc: 0.9583 - val_loss: 0.3353 - val_acc: 0.9000\n",
            "Epoch 70/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2680 - acc: 0.9750 - val_loss: 0.3286 - val_acc: 0.9000\n",
            "Epoch 71/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2697 - acc: 0.9750 - val_loss: 0.3357 - val_acc: 0.8667\n",
            "Epoch 72/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2661 - acc: 0.9583 - val_loss: 0.3250 - val_acc: 0.9333\n",
            "Epoch 73/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2621 - acc: 0.9750 - val_loss: 0.3212 - val_acc: 0.9333\n",
            "Epoch 74/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2634 - acc: 0.9500 - val_loss: 0.3047 - val_acc: 0.9333\n",
            "Epoch 75/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2620 - acc: 0.9750 - val_loss: 0.3153 - val_acc: 0.9333\n",
            "Epoch 76/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2588 - acc: 0.9750 - val_loss: 0.3264 - val_acc: 0.8667\n",
            "Epoch 77/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2583 - acc: 0.9667 - val_loss: 0.3281 - val_acc: 0.8667\n",
            "Epoch 78/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2580 - acc: 0.9750 - val_loss: 0.3255 - val_acc: 0.8667\n",
            "Epoch 79/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2540 - acc: 0.9750 - val_loss: 0.3143 - val_acc: 0.9333\n",
            "Epoch 80/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2527 - acc: 0.9750 - val_loss: 0.3079 - val_acc: 0.9333\n",
            "Epoch 81/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2513 - acc: 0.9667 - val_loss: 0.3154 - val_acc: 0.9333\n",
            "Epoch 82/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2493 - acc: 0.9750 - val_loss: 0.3104 - val_acc: 0.9333\n",
            "Epoch 83/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2482 - acc: 0.9750 - val_loss: 0.3075 - val_acc: 0.9333\n",
            "Epoch 84/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2471 - acc: 0.9750 - val_loss: 0.3047 - val_acc: 0.9333\n",
            "Epoch 85/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2438 - acc: 0.9750 - val_loss: 0.2917 - val_acc: 0.9333\n",
            "Epoch 86/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2418 - acc: 0.9750 - val_loss: 0.2980 - val_acc: 0.9333\n",
            "Epoch 87/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2415 - acc: 0.9750 - val_loss: 0.3095 - val_acc: 0.9333\n",
            "Epoch 88/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2403 - acc: 0.9750 - val_loss: 0.3094 - val_acc: 0.9000\n",
            "Epoch 89/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2394 - acc: 0.9750 - val_loss: 0.3032 - val_acc: 0.9333\n",
            "Epoch 90/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2355 - acc: 0.9750 - val_loss: 0.2915 - val_acc: 0.9333\n",
            "Epoch 91/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2356 - acc: 0.9750 - val_loss: 0.2849 - val_acc: 0.9333\n",
            "Epoch 92/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2333 - acc: 0.9750 - val_loss: 0.2947 - val_acc: 0.9333\n",
            "Epoch 93/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2326 - acc: 0.9750 - val_loss: 0.2872 - val_acc: 0.9333\n",
            "Epoch 94/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2300 - acc: 0.9750 - val_loss: 0.2809 - val_acc: 0.9333\n",
            "Epoch 95/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2295 - acc: 0.9750 - val_loss: 0.2944 - val_acc: 0.9333\n",
            "Epoch 96/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2304 - acc: 0.9750 - val_loss: 0.2841 - val_acc: 0.9333\n",
            "Epoch 97/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2281 - acc: 0.9750 - val_loss: 0.2908 - val_acc: 0.9333\n",
            "Epoch 98/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2281 - acc: 0.9750 - val_loss: 0.2848 - val_acc: 0.9333\n",
            "Epoch 99/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2235 - acc: 0.9750 - val_loss: 0.2777 - val_acc: 0.9333\n",
            "Epoch 100/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2236 - acc: 0.9667 - val_loss: 0.2742 - val_acc: 0.9333\n",
            "Epoch 101/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2234 - acc: 0.9833 - val_loss: 0.2745 - val_acc: 0.9333\n",
            "Epoch 102/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2208 - acc: 0.9750 - val_loss: 0.2721 - val_acc: 0.9333\n",
            "Epoch 103/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2186 - acc: 0.9750 - val_loss: 0.2741 - val_acc: 0.9333\n",
            "Epoch 104/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2190 - acc: 0.9750 - val_loss: 0.2680 - val_acc: 0.9333\n",
            "Epoch 105/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2178 - acc: 0.9750 - val_loss: 0.2652 - val_acc: 0.9333\n",
            "Epoch 106/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2159 - acc: 0.9750 - val_loss: 0.2614 - val_acc: 0.9667\n",
            "Epoch 107/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2150 - acc: 0.9750 - val_loss: 0.2793 - val_acc: 0.9333\n",
            "Epoch 108/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2160 - acc: 0.9750 - val_loss: 0.2836 - val_acc: 0.9000\n",
            "Epoch 109/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2126 - acc: 0.9750 - val_loss: 0.2711 - val_acc: 0.9333\n",
            "Epoch 110/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2108 - acc: 0.9750 - val_loss: 0.2657 - val_acc: 0.9333\n",
            "Epoch 111/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2109 - acc: 0.9750 - val_loss: 0.2612 - val_acc: 0.9333\n",
            "Epoch 112/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2090 - acc: 0.9750 - val_loss: 0.2585 - val_acc: 0.9333\n",
            "Epoch 113/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2079 - acc: 0.9750 - val_loss: 0.2564 - val_acc: 0.9667\n",
            "Epoch 114/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2079 - acc: 0.9750 - val_loss: 0.2610 - val_acc: 0.9333\n",
            "Epoch 115/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2043 - acc: 0.9750 - val_loss: 0.2586 - val_acc: 0.9333\n",
            "Epoch 116/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2039 - acc: 0.9833 - val_loss: 0.2690 - val_acc: 0.9333\n",
            "Epoch 117/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2068 - acc: 0.9750 - val_loss: 0.2471 - val_acc: 0.9667\n",
            "Epoch 118/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2012 - acc: 0.9833 - val_loss: 0.2642 - val_acc: 0.9333\n",
            "Epoch 119/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.2005 - acc: 0.9750 - val_loss: 0.2471 - val_acc: 0.9667\n",
            "Epoch 120/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1997 - acc: 0.9750 - val_loss: 0.2586 - val_acc: 0.9333\n",
            "Epoch 121/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1999 - acc: 0.9750 - val_loss: 0.2552 - val_acc: 0.9333\n",
            "Epoch 122/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1986 - acc: 0.9750 - val_loss: 0.2568 - val_acc: 0.9333\n",
            "Epoch 123/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1998 - acc: 0.9833 - val_loss: 0.2550 - val_acc: 0.9333\n",
            "Epoch 124/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1963 - acc: 0.9750 - val_loss: 0.2520 - val_acc: 0.9333\n",
            "Epoch 125/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1967 - acc: 0.9750 - val_loss: 0.2595 - val_acc: 0.9333\n",
            "Epoch 126/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1944 - acc: 0.9750 - val_loss: 0.2468 - val_acc: 0.9333\n",
            "Epoch 127/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1931 - acc: 0.9750 - val_loss: 0.2530 - val_acc: 0.9333\n",
            "Epoch 128/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1922 - acc: 0.9750 - val_loss: 0.2515 - val_acc: 0.9333\n",
            "Epoch 129/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1912 - acc: 0.9750 - val_loss: 0.2424 - val_acc: 0.9667\n",
            "Epoch 130/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1901 - acc: 0.9750 - val_loss: 0.2518 - val_acc: 0.9333\n",
            "Epoch 131/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1906 - acc: 0.9750 - val_loss: 0.2455 - val_acc: 0.9333\n",
            "Epoch 132/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1889 - acc: 0.9750 - val_loss: 0.2450 - val_acc: 0.9333\n",
            "Epoch 133/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1894 - acc: 0.9750 - val_loss: 0.2419 - val_acc: 0.9333\n",
            "Epoch 134/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1887 - acc: 0.9750 - val_loss: 0.2376 - val_acc: 0.9667\n",
            "Epoch 135/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1875 - acc: 0.9750 - val_loss: 0.2444 - val_acc: 0.9333\n",
            "Epoch 136/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1859 - acc: 0.9750 - val_loss: 0.2366 - val_acc: 0.9667\n",
            "Epoch 137/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1864 - acc: 0.9750 - val_loss: 0.2319 - val_acc: 0.9667\n",
            "Epoch 138/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1836 - acc: 0.9667 - val_loss: 0.2373 - val_acc: 0.9333\n",
            "Epoch 139/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1831 - acc: 0.9750 - val_loss: 0.2351 - val_acc: 0.9667\n",
            "Epoch 140/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1824 - acc: 0.9667 - val_loss: 0.2419 - val_acc: 0.9333\n",
            "Epoch 141/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1830 - acc: 0.9750 - val_loss: 0.2271 - val_acc: 0.9667\n",
            "Epoch 142/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1799 - acc: 0.9833 - val_loss: 0.2373 - val_acc: 0.9333\n",
            "Epoch 143/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1804 - acc: 0.9750 - val_loss: 0.2323 - val_acc: 0.9667\n",
            "Epoch 144/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1794 - acc: 0.9750 - val_loss: 0.2377 - val_acc: 0.9333\n",
            "Epoch 145/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1803 - acc: 0.9750 - val_loss: 0.2344 - val_acc: 0.9333\n",
            "Epoch 146/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1777 - acc: 0.9750 - val_loss: 0.2310 - val_acc: 0.9667\n",
            "Epoch 147/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1761 - acc: 0.9833 - val_loss: 0.2322 - val_acc: 0.9333\n",
            "Epoch 148/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1767 - acc: 0.9750 - val_loss: 0.2239 - val_acc: 0.9667\n",
            "Epoch 149/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1750 - acc: 0.9833 - val_loss: 0.2323 - val_acc: 0.9333\n",
            "Epoch 150/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1768 - acc: 0.9750 - val_loss: 0.2240 - val_acc: 0.9667\n",
            "Epoch 151/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1757 - acc: 0.9750 - val_loss: 0.2212 - val_acc: 0.9667\n",
            "Epoch 152/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1736 - acc: 0.9750 - val_loss: 0.2200 - val_acc: 0.9667\n",
            "Epoch 153/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1727 - acc: 0.9750 - val_loss: 0.2248 - val_acc: 0.9667\n",
            "Epoch 154/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1710 - acc: 0.9750 - val_loss: 0.2179 - val_acc: 0.9667\n",
            "Epoch 155/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1720 - acc: 0.9750 - val_loss: 0.2210 - val_acc: 0.9667\n",
            "Epoch 156/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1716 - acc: 0.9833 - val_loss: 0.2233 - val_acc: 0.9667\n",
            "Epoch 157/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1693 - acc: 0.9750 - val_loss: 0.2173 - val_acc: 0.9667\n",
            "Epoch 158/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1698 - acc: 0.9750 - val_loss: 0.2204 - val_acc: 0.9667\n",
            "Epoch 159/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1686 - acc: 0.9833 - val_loss: 0.2220 - val_acc: 0.9667\n",
            "Epoch 160/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1668 - acc: 0.9750 - val_loss: 0.2143 - val_acc: 0.9667\n",
            "Epoch 161/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1681 - acc: 0.9750 - val_loss: 0.2169 - val_acc: 0.9667\n",
            "Epoch 162/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1664 - acc: 0.9833 - val_loss: 0.2095 - val_acc: 0.9667\n",
            "Epoch 163/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1657 - acc: 0.9750 - val_loss: 0.2138 - val_acc: 0.9667\n",
            "Epoch 164/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1637 - acc: 0.9750 - val_loss: 0.2027 - val_acc: 0.9667\n",
            "Epoch 165/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1683 - acc: 0.9750 - val_loss: 0.2091 - val_acc: 0.9667\n",
            "Epoch 166/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1643 - acc: 0.9750 - val_loss: 0.2125 - val_acc: 0.9667\n",
            "Epoch 167/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1623 - acc: 0.9750 - val_loss: 0.2105 - val_acc: 0.9667\n",
            "Epoch 168/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1642 - acc: 0.9750 - val_loss: 0.2062 - val_acc: 0.9667\n",
            "Epoch 169/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1639 - acc: 0.9667 - val_loss: 0.2118 - val_acc: 0.9667\n",
            "Epoch 170/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1623 - acc: 0.9750 - val_loss: 0.2064 - val_acc: 0.9667\n",
            "Epoch 171/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1620 - acc: 0.9750 - val_loss: 0.2014 - val_acc: 0.9667\n",
            "Epoch 172/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1622 - acc: 0.9583 - val_loss: 0.2063 - val_acc: 0.9667\n",
            "Epoch 173/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1605 - acc: 0.9667 - val_loss: 0.2108 - val_acc: 0.9667\n",
            "Epoch 174/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1597 - acc: 0.9750 - val_loss: 0.2185 - val_acc: 0.9333\n",
            "Epoch 175/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1594 - acc: 0.9750 - val_loss: 0.2063 - val_acc: 0.9667\n",
            "Epoch 176/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1575 - acc: 0.9750 - val_loss: 0.2070 - val_acc: 0.9667\n",
            "Epoch 177/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1575 - acc: 0.9750 - val_loss: 0.1977 - val_acc: 0.9667\n",
            "Epoch 178/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1569 - acc: 0.9750 - val_loss: 0.2018 - val_acc: 0.9667\n",
            "Epoch 179/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1560 - acc: 0.9833 - val_loss: 0.2069 - val_acc: 0.9667\n",
            "Epoch 180/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1559 - acc: 0.9750 - val_loss: 0.1972 - val_acc: 0.9667\n",
            "Epoch 181/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1557 - acc: 0.9833 - val_loss: 0.2029 - val_acc: 0.9667\n",
            "Epoch 182/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1557 - acc: 0.9750 - val_loss: 0.1997 - val_acc: 0.9667\n",
            "Epoch 183/200\n",
            "120/120 [==============================] - 0s 2ms/sample - loss: 0.1563 - acc: 0.9667 - val_loss: 0.2057 - val_acc: 0.9667\n",
            "Epoch 184/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1541 - acc: 0.9750 - val_loss: 0.1959 - val_acc: 0.9667\n",
            "Epoch 185/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1533 - acc: 0.9833 - val_loss: 0.2043 - val_acc: 0.9667\n",
            "Epoch 186/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1533 - acc: 0.9833 - val_loss: 0.1964 - val_acc: 0.9667\n",
            "Epoch 187/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1536 - acc: 0.9750 - val_loss: 0.1904 - val_acc: 0.9667\n",
            "Epoch 188/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1528 - acc: 0.9750 - val_loss: 0.1871 - val_acc: 1.0000\n",
            "Epoch 189/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1515 - acc: 0.9750 - val_loss: 0.1937 - val_acc: 0.9667\n",
            "Epoch 190/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1499 - acc: 0.9750 - val_loss: 0.1963 - val_acc: 0.9667\n",
            "Epoch 191/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1497 - acc: 0.9750 - val_loss: 0.1881 - val_acc: 0.9667\n",
            "Epoch 192/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1524 - acc: 0.9750 - val_loss: 0.1889 - val_acc: 0.9667\n",
            "Epoch 193/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1525 - acc: 0.9750 - val_loss: 0.1966 - val_acc: 0.9667\n",
            "Epoch 194/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1499 - acc: 0.9750 - val_loss: 0.1902 - val_acc: 0.9667\n",
            "Epoch 195/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1471 - acc: 0.9750 - val_loss: 0.2005 - val_acc: 0.9667\n",
            "Epoch 196/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1485 - acc: 0.9750 - val_loss: 0.2021 - val_acc: 0.9667\n",
            "Epoch 197/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1475 - acc: 0.9833 - val_loss: 0.1939 - val_acc: 0.9667\n",
            "Epoch 198/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1468 - acc: 0.9750 - val_loss: 0.1886 - val_acc: 0.9667\n",
            "Epoch 199/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1472 - acc: 0.9750 - val_loss: 0.1820 - val_acc: 1.0000\n",
            "Epoch 200/200\n",
            "120/120 [==============================] - 0s 1ms/sample - loss: 0.1461 - acc: 0.9750 - val_loss: 0.1831 - val_acc: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHFvTJe_kpd4",
        "colab_type": "text"
      },
      "source": [
        "앞서 실습한 코드들과 거의 동일한데 달라진 점은 입력의 차원이 4로 바뀌면서, input_dim의 인자값이 4로 바뀌었다는 점과 이제 출력의 차원이 3이므로 input_dim=4 앞의 인자값이 3으로 바뀌었다는 점입니다. 또한 함수로는 소프트맥스 함수를 사용하므로 activation에는 softmax를 기재해줍니다.\n",
        "\n",
        "오차 함수로는 크로스 엔트로피 함수를 사용합니다. 이진 분류 문제에서는 binary_crossentropy를 사용하였지만, 다중 클래스 분류 문제에서는 'categorical_crossentropy를 기재해주어야 합니다. 옵티마이저로는 경사 하강법의 일종인 adam을 사용합니다. 전체 데이터에 대한 훈련 횟수는 200회로 주었습니다. 이번에는 테스트 데이터를 별도로 분리해서 평가에 사용하였는데, validation_data=()에 테스트 데이터를 기재해주면 실제로는 훈련에는 반영되지 않으면서 각 훈련 횟수마다 테스트 데이터에 대한 정확도를 출력합니다. 즉, 정확도가 전체 데이터에 대한 훈련 1회(1 에포크)마다 측정되고는 있지만 기계는 저 데이터를 가지고는 가중치를 업데이트하지 않습니다. 이해가 되지 않는다면 뒤의 로이터 뉴스 분류하기 챕터에서 다시 설명하므로 여기서는 넘어가도 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq69TaqQlFnh",
        "colab_type": "text"
      },
      "source": [
        "acc은 훈련 데이터에 대한 정확도이고, val_acc은 테스트 데이터에 대한 정확도를 의미합니다. 훈련 데이터에서는 95%의 정확도를 보이고, 테스트 데이터에 대해서는 100%의 정확도를 보입니다. 이번에는 각 에포크당 훈련 데이터와 테스트 데이터에 대한 정확도를 측정했으므로 한 번 에포크에 따른 정확도를 그래프로 출력해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__485KJlcJ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "d50622b4-c3eb-487c-91c6-23d97a78963c"
      },
      "source": [
        "print('테스트 정확도')\n",
        "print(model.evaluate(X_test, y_test)[0])  #150개 중에서 80프로가(120개)훈련데이타니까 나머지 30개가 테스트 개수."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "테스트 정확도\n",
            "\r30/30 [==============================] - 0s 46us/sample - loss: 0.1831 - acc: 0.9667\n",
            "0.18313001096248627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwuvN_llmFCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62ce4edf-5a42-485e-9ad7-68d5e986462e"
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.8, 4. , 1.2, 0.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BQaHW-rmHtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7c5d384-26bd-4db9-9be3-bd1a1604d141"
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEOEXCF7lO2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4719078a-1d93-4577-cc36-f94e36e4c20d"
      },
      "source": [
        "model.predict(X_test)[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.9993277e-01, 6.7225330e-05, 3.5195039e-10], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHQqPUtFl78J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
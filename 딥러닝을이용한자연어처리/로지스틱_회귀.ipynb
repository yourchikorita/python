{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "케라스로 구현하는 로지스틱 회귀.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgZNQTHJGYSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "626aca19-7869-40b1-e2f5-e80df690b5c0"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential # 케라스의 Sequential()을 임포트\n",
        "from tensorflow.keras.layers import Dense # 케라스의 Dense()를 임포트\n",
        "from tensorflow.keras import optimizers # 케라스의 옵티마이저를 임포트\n",
        "\n",
        "X=np.array([-50, -40, -30, -20, -10, -5, 0, 5, 10, 20, 30, 40, 50])\n",
        "y=np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]) #숫자 10부터 1\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
        "sgd=optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=sgd ,loss='binary_crossentropy',metrics=['binary_accuracy'])\n",
        "# 옵티마이저는 경사하강법의 일종인 확률적 경사 하강법 sgd를 사용합니다.\n",
        "# 손실 함수(Loss function)는 binary_crossentropy(이진 크로스 엔트로피)를 사용합니다.\n",
        "model.fit(X,y, batch_size=1, epochs=200, shuffle=False)\n",
        "# 주어진 X와 y데이터에 대해서 오차를 최소화하는 작업을 200번 시도합니다."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 13 samples\n",
            "Epoch 1/200\n",
            "13/13 [==============================] - 0s 21ms/sample - loss: 1.7905 - binary_accuracy: 0.8462\n",
            "Epoch 2/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.2078 - binary_accuracy: 0.9231\n",
            "Epoch 3/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.2035 - binary_accuracy: 0.9231\n",
            "Epoch 4/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.2010 - binary_accuracy: 0.9231\n",
            "Epoch 5/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1990 - binary_accuracy: 0.9231\n",
            "Epoch 6/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1973 - binary_accuracy: 0.9231\n",
            "Epoch 7/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1956 - binary_accuracy: 0.9231\n",
            "Epoch 8/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1940 - binary_accuracy: 0.9231\n",
            "Epoch 9/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1925 - binary_accuracy: 0.9231\n",
            "Epoch 10/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1910 - binary_accuracy: 0.9231\n",
            "Epoch 11/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1895 - binary_accuracy: 0.9231\n",
            "Epoch 12/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1880 - binary_accuracy: 0.9231\n",
            "Epoch 13/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1866 - binary_accuracy: 0.9231\n",
            "Epoch 14/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1851 - binary_accuracy: 0.9231\n",
            "Epoch 15/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1838 - binary_accuracy: 0.9231\n",
            "Epoch 16/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1824 - binary_accuracy: 0.9231\n",
            "Epoch 17/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1810 - binary_accuracy: 0.9231\n",
            "Epoch 18/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1797 - binary_accuracy: 0.9231\n",
            "Epoch 19/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1784 - binary_accuracy: 0.9231\n",
            "Epoch 20/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1771 - binary_accuracy: 0.9231\n",
            "Epoch 21/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1759 - binary_accuracy: 0.9231\n",
            "Epoch 22/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1746 - binary_accuracy: 0.9231\n",
            "Epoch 23/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1734 - binary_accuracy: 0.9231\n",
            "Epoch 24/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1722 - binary_accuracy: 0.9231\n",
            "Epoch 25/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1710 - binary_accuracy: 0.9231\n",
            "Epoch 26/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1698 - binary_accuracy: 0.9231\n",
            "Epoch 27/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1687 - binary_accuracy: 0.9231\n",
            "Epoch 28/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1675 - binary_accuracy: 0.9231\n",
            "Epoch 29/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1664 - binary_accuracy: 0.9231\n",
            "Epoch 30/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1653 - binary_accuracy: 0.9231\n",
            "Epoch 31/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1643 - binary_accuracy: 0.9231\n",
            "Epoch 32/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1632 - binary_accuracy: 0.9231\n",
            "Epoch 33/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1621 - binary_accuracy: 0.9231\n",
            "Epoch 34/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1611 - binary_accuracy: 0.9231\n",
            "Epoch 35/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1601 - binary_accuracy: 0.9231\n",
            "Epoch 36/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1591 - binary_accuracy: 0.9231\n",
            "Epoch 37/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1581 - binary_accuracy: 0.9231\n",
            "Epoch 38/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1571 - binary_accuracy: 0.9231\n",
            "Epoch 39/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1562 - binary_accuracy: 0.9231\n",
            "Epoch 40/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1552 - binary_accuracy: 0.9231\n",
            "Epoch 41/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1543 - binary_accuracy: 0.9231\n",
            "Epoch 42/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1534 - binary_accuracy: 0.9231\n",
            "Epoch 43/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1525 - binary_accuracy: 0.9231\n",
            "Epoch 44/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1516 - binary_accuracy: 0.9231\n",
            "Epoch 45/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1507 - binary_accuracy: 0.9231\n",
            "Epoch 46/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1499 - binary_accuracy: 0.9231\n",
            "Epoch 47/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1490 - binary_accuracy: 0.9231\n",
            "Epoch 48/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1482 - binary_accuracy: 0.9231\n",
            "Epoch 49/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1474 - binary_accuracy: 0.9231\n",
            "Epoch 50/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1466 - binary_accuracy: 0.9231\n",
            "Epoch 51/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1458 - binary_accuracy: 0.9231\n",
            "Epoch 52/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1450 - binary_accuracy: 0.9231\n",
            "Epoch 53/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1442 - binary_accuracy: 0.9231\n",
            "Epoch 54/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1434 - binary_accuracy: 0.9231\n",
            "Epoch 55/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1427 - binary_accuracy: 0.9231\n",
            "Epoch 56/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1419 - binary_accuracy: 0.9231\n",
            "Epoch 57/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1412 - binary_accuracy: 0.9231\n",
            "Epoch 58/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1404 - binary_accuracy: 0.9231\n",
            "Epoch 59/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1397 - binary_accuracy: 0.9231\n",
            "Epoch 60/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1390 - binary_accuracy: 0.9231\n",
            "Epoch 61/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1383 - binary_accuracy: 0.9231\n",
            "Epoch 62/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1376 - binary_accuracy: 0.9231\n",
            "Epoch 63/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1369 - binary_accuracy: 0.9231\n",
            "Epoch 64/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1363 - binary_accuracy: 0.9231\n",
            "Epoch 65/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1356 - binary_accuracy: 0.9231\n",
            "Epoch 66/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1350 - binary_accuracy: 0.9231\n",
            "Epoch 67/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1343 - binary_accuracy: 0.9231\n",
            "Epoch 68/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1337 - binary_accuracy: 0.9231\n",
            "Epoch 69/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1330 - binary_accuracy: 0.9231\n",
            "Epoch 70/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1324 - binary_accuracy: 0.9231\n",
            "Epoch 71/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1318 - binary_accuracy: 0.9231\n",
            "Epoch 72/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1312 - binary_accuracy: 0.9231\n",
            "Epoch 73/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1306 - binary_accuracy: 0.9231\n",
            "Epoch 74/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1300 - binary_accuracy: 0.9231\n",
            "Epoch 75/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1294 - binary_accuracy: 0.9231\n",
            "Epoch 76/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1288 - binary_accuracy: 0.9231\n",
            "Epoch 77/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1283 - binary_accuracy: 0.9231\n",
            "Epoch 78/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1277 - binary_accuracy: 0.9231\n",
            "Epoch 79/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1272 - binary_accuracy: 0.9231\n",
            "Epoch 80/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1266 - binary_accuracy: 0.9231\n",
            "Epoch 81/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1261 - binary_accuracy: 0.9231\n",
            "Epoch 82/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1255 - binary_accuracy: 0.9231\n",
            "Epoch 83/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1250 - binary_accuracy: 0.9231\n",
            "Epoch 84/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1245 - binary_accuracy: 0.9231\n",
            "Epoch 85/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1239 - binary_accuracy: 0.9231\n",
            "Epoch 86/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1234 - binary_accuracy: 0.9231\n",
            "Epoch 87/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1229 - binary_accuracy: 0.9231\n",
            "Epoch 88/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1224 - binary_accuracy: 0.9231\n",
            "Epoch 89/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1219 - binary_accuracy: 0.9231\n",
            "Epoch 90/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1214 - binary_accuracy: 0.9231\n",
            "Epoch 91/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1210 - binary_accuracy: 0.9231\n",
            "Epoch 92/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1205 - binary_accuracy: 0.9231\n",
            "Epoch 93/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1200 - binary_accuracy: 0.9231\n",
            "Epoch 94/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1195 - binary_accuracy: 0.9231\n",
            "Epoch 95/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1191 - binary_accuracy: 0.9231\n",
            "Epoch 96/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1186 - binary_accuracy: 0.9231\n",
            "Epoch 97/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1182 - binary_accuracy: 0.9231\n",
            "Epoch 98/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1177 - binary_accuracy: 0.9231\n",
            "Epoch 99/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1173 - binary_accuracy: 0.9231\n",
            "Epoch 100/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1168 - binary_accuracy: 0.9231\n",
            "Epoch 101/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1164 - binary_accuracy: 0.9231\n",
            "Epoch 102/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1160 - binary_accuracy: 0.9231\n",
            "Epoch 103/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1155 - binary_accuracy: 0.9231\n",
            "Epoch 104/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1151 - binary_accuracy: 0.9231\n",
            "Epoch 105/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1147 - binary_accuracy: 0.9231\n",
            "Epoch 106/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1143 - binary_accuracy: 0.9231\n",
            "Epoch 107/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1139 - binary_accuracy: 0.9231\n",
            "Epoch 108/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1135 - binary_accuracy: 0.9231\n",
            "Epoch 109/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1131 - binary_accuracy: 0.9231\n",
            "Epoch 110/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1127 - binary_accuracy: 0.9231\n",
            "Epoch 111/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1123 - binary_accuracy: 0.9231\n",
            "Epoch 112/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1119 - binary_accuracy: 0.9231\n",
            "Epoch 113/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1115 - binary_accuracy: 0.9231\n",
            "Epoch 114/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1112 - binary_accuracy: 0.9231\n",
            "Epoch 115/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1108 - binary_accuracy: 0.9231\n",
            "Epoch 116/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1104 - binary_accuracy: 0.9231\n",
            "Epoch 117/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1100 - binary_accuracy: 0.9231\n",
            "Epoch 118/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1097 - binary_accuracy: 0.9231\n",
            "Epoch 119/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1093 - binary_accuracy: 0.9231\n",
            "Epoch 120/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1090 - binary_accuracy: 0.9231\n",
            "Epoch 121/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1086 - binary_accuracy: 0.9231\n",
            "Epoch 122/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1082 - binary_accuracy: 0.9231\n",
            "Epoch 123/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1079 - binary_accuracy: 0.9231\n",
            "Epoch 124/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1076 - binary_accuracy: 0.9231\n",
            "Epoch 125/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1072 - binary_accuracy: 0.9231\n",
            "Epoch 126/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1069 - binary_accuracy: 0.9231\n",
            "Epoch 127/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1065 - binary_accuracy: 0.9231\n",
            "Epoch 128/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1062 - binary_accuracy: 0.9231\n",
            "Epoch 129/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1059 - binary_accuracy: 0.9231\n",
            "Epoch 130/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1056 - binary_accuracy: 0.9231\n",
            "Epoch 131/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1052 - binary_accuracy: 0.9231\n",
            "Epoch 132/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1049 - binary_accuracy: 0.9231\n",
            "Epoch 133/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1046 - binary_accuracy: 0.9231\n",
            "Epoch 134/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1043 - binary_accuracy: 0.9231\n",
            "Epoch 135/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1040 - binary_accuracy: 0.9231\n",
            "Epoch 136/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1037 - binary_accuracy: 0.9231\n",
            "Epoch 137/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1033 - binary_accuracy: 0.9231\n",
            "Epoch 138/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1030 - binary_accuracy: 0.9231\n",
            "Epoch 139/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1027 - binary_accuracy: 0.9231\n",
            "Epoch 140/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1024 - binary_accuracy: 0.9231\n",
            "Epoch 141/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1021 - binary_accuracy: 0.9231\n",
            "Epoch 142/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1019 - binary_accuracy: 0.9231\n",
            "Epoch 143/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1016 - binary_accuracy: 0.9231\n",
            "Epoch 144/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1013 - binary_accuracy: 0.9231\n",
            "Epoch 145/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1010 - binary_accuracy: 0.9231\n",
            "Epoch 146/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1007 - binary_accuracy: 0.9231\n",
            "Epoch 147/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.1004 - binary_accuracy: 0.9231\n",
            "Epoch 148/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.1001 - binary_accuracy: 0.9231\n",
            "Epoch 149/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0999 - binary_accuracy: 0.9231\n",
            "Epoch 150/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0996 - binary_accuracy: 0.9231\n",
            "Epoch 151/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0993 - binary_accuracy: 0.9231\n",
            "Epoch 152/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0991 - binary_accuracy: 0.9231\n",
            "Epoch 153/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0988 - binary_accuracy: 0.9231\n",
            "Epoch 154/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0985 - binary_accuracy: 0.9231\n",
            "Epoch 155/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0983 - binary_accuracy: 0.9231\n",
            "Epoch 156/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0980 - binary_accuracy: 0.9231\n",
            "Epoch 157/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0977 - binary_accuracy: 0.9231\n",
            "Epoch 158/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0975 - binary_accuracy: 0.9231\n",
            "Epoch 159/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0972 - binary_accuracy: 0.9231\n",
            "Epoch 160/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0970 - binary_accuracy: 0.9231\n",
            "Epoch 161/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0967 - binary_accuracy: 0.9231\n",
            "Epoch 162/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0965 - binary_accuracy: 0.9231\n",
            "Epoch 163/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0962 - binary_accuracy: 0.9231\n",
            "Epoch 164/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0960 - binary_accuracy: 0.9231\n",
            "Epoch 165/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0957 - binary_accuracy: 0.9231\n",
            "Epoch 166/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0955 - binary_accuracy: 0.9231\n",
            "Epoch 167/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0952 - binary_accuracy: 0.9231\n",
            "Epoch 168/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0950 - binary_accuracy: 0.9231\n",
            "Epoch 169/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0948 - binary_accuracy: 0.9231\n",
            "Epoch 170/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0945 - binary_accuracy: 0.9231\n",
            "Epoch 171/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0943 - binary_accuracy: 0.9231\n",
            "Epoch 172/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0941 - binary_accuracy: 0.9231\n",
            "Epoch 173/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0938 - binary_accuracy: 0.9231\n",
            "Epoch 174/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0936 - binary_accuracy: 0.9231\n",
            "Epoch 175/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0934 - binary_accuracy: 0.9231\n",
            "Epoch 176/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0932 - binary_accuracy: 0.9231\n",
            "Epoch 177/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0929 - binary_accuracy: 0.9231\n",
            "Epoch 178/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0927 - binary_accuracy: 0.9231\n",
            "Epoch 179/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0925 - binary_accuracy: 0.9231\n",
            "Epoch 180/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0923 - binary_accuracy: 0.9231\n",
            "Epoch 181/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0921 - binary_accuracy: 0.9231\n",
            "Epoch 182/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0918 - binary_accuracy: 0.9231\n",
            "Epoch 183/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0916 - binary_accuracy: 0.9231\n",
            "Epoch 184/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0914 - binary_accuracy: 0.9231\n",
            "Epoch 185/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0912 - binary_accuracy: 0.9231\n",
            "Epoch 186/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0910 - binary_accuracy: 0.9231\n",
            "Epoch 187/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0908 - binary_accuracy: 0.9231\n",
            "Epoch 188/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0906 - binary_accuracy: 0.9231\n",
            "Epoch 189/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0904 - binary_accuracy: 0.9231\n",
            "Epoch 190/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0902 - binary_accuracy: 0.9231\n",
            "Epoch 191/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0900 - binary_accuracy: 0.9231\n",
            "Epoch 192/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0898 - binary_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0896 - binary_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0894 - binary_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0892 - binary_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0890 - binary_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0888 - binary_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0886 - binary_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "13/13 [==============================] - 0s 2ms/sample - loss: 0.0884 - binary_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "13/13 [==============================] - 0s 1ms/sample - loss: 0.0882 - binary_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3885333fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYqv8UmhJQCO",
        "colab_type": "text"
      },
      "source": [
        "임의의 숫자들의 나열을 X라고 하였을 때, 숫자 10 이상인 경우에는 1, 미만인 경우에는 0을 부여한 레이블 데이터를 y라고 해봅시다. 이번 데이터는 앞서 배운 단순 선형 회귀때와 마찬가지로 1개의 실수인 X로부터 1개의 실수인 y를 예측하는 맵핑 관계를 가지므로 각각 1을 기재합니다. 또한 시그모이드 함수를 사용할 것이므로 activation에 sigmoid를 기재해줍니다.\n",
        "\n",
        "옵티마이저로는 경사 하강법의 일종인 확률적 경사 하강법을 사용하였으며, 손실 함수로는 크로스 엔트로피 함수를 사용합니다. 이진 분류 문제에 크로스 엔트로피 함수를 사용할 경우에는 binary_crossentropy를 기재해주면 됩니다. 전체 데이터에 대한 훈련 횟수는 200으로 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6dPwphZJSzZ",
        "colab_type": "text"
      },
      "source": [
        "총 200회에 걸쳐 전체 데이터에 대한 오차를 최소화하는 W와 b를 찾아내는 작업을 합니다. 약 190회부터 정확도가 100%가 나오기 시작했습니다. 실제값과 오차를 최소화하는 W와 b의 값을 가진 시그모이드 함수 그래프를 그려보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwittBoZJNye",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e769dfce-c512-40a0-8585-f5df57ba09cc"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(X, model.predict(X), 'b', X,y, 'k.')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f387ccc51d0>,\n",
              " <matplotlib.lines.Line2D at 0x7f387ccc5320>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUkJBbqISEr8L8cG3jhVGJ64AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82W3i1heJWxB",
        "colab_type": "text"
      },
      "source": [
        "X값이 5와 10사이의 어떤 값일때 y값이 0.5가 넘기 시작하는 것처럼 보입니다. 정확도가 100%가 나왔었기 때문에 적어도 X값이 5일때는 y값이 0.5보다 작고, X값이 10일 때는 y값이 0.5를 넘을 것입니다. 이제 X값이 5보다 작은 값일 때와 X값이 10보다 클 때에 대해서 y값을 출력해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1quegv5JUrd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "d82003e3-02ce-4245-e46f-3d92507c9024"
      },
      "source": [
        "print(model.predict([1, 2, 3, 4, 4.5]))\n",
        "print(model.predict([11, 21, 31, 41, 500]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.21056446]\n",
            " [0.26893088]\n",
            " [0.3365781 ]\n",
            " [0.41165975]\n",
            " [0.45106417]]\n",
            "[[0.86912006]\n",
            " [0.9939878 ]\n",
            " [0.9997571 ]\n",
            " [0.9999902 ]\n",
            " [1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pxZzMNZJakr",
        "colab_type": "text"
      },
      "source": [
        "X값이 5보다 작을 때는 0.5보다 작은 값을, X값이 10보다 클 때는 0.5보다 큰 값을 출력하는 것을 볼 수 있습니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83dZEsvyJYTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}